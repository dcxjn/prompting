{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfhislp9gWT3",
        "outputId": "99cecbe9-1ca0-46b3-9de6-b60a6413c186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install torch\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dENdfOSxYz7z",
        "outputId": "e61b309a-e2c6-4dec-91d7-cc3e747e4ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/content/prompting' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dcxjn/prompting.git /content/prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WtLdisLkY0ye"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/prompting')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P8aMfDc7Y0_z"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/prompting')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KwF9eXQoYtjC"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "import accelerate\n",
        "\n",
        "from src.utils.image_util import load_image, resize_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p-UOjRhuYtjD"
      },
      "outputs": [],
      "source": [
        "def query(inputs: dict) -> dict:\n",
        "        \n",
        "    model_id = \"llava-hf/llava-v1.6-vicuna-13b-hf\"\n",
        "\n",
        "    # Configure BitsAndBytesConfig based on GPU availability\n",
        "    if torch.cuda.is_available():\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "    else:\n",
        "        quantization_config = None  # or configure for CPU if necessary\n",
        "\n",
        "    # Initialize pipeline based on GPU availability\n",
        "    if torch.cuda.is_available():\n",
        "        pipe = pipeline(\n",
        "            \"image-to-text\",\n",
        "            model=model_id,\n",
        "            model_kwargs={\"quantization_config\": quantization_config},\n",
        "            # device=0,  # commented out for Google Colab\n",
        "        )\n",
        "    else:\n",
        "        pipe = pipeline(\n",
        "            \"image-to-text\",\n",
        "            model=model_id,\n",
        "            model_kwargs={\"quantization_config\": quantization_config},\n",
        "        )\n",
        "\n",
        "    image = inputs[\"image\"]\n",
        "\n",
        "    prompt1 = f\"\"\"\n",
        "    Observe the given image and its details.\n",
        "    Provide a detailed step-by-step guide on how a human would complete the task of: {inputs[\"task\"]}.\n",
        "    Link each instruction to an observation in the image in this format: \"Observation - Instruction\".\n",
        "    \"\"\"\n",
        "\n",
        "    prompt2 = f\"\"\"\n",
        "    Imagine you are in control of a robotic arm with the following commands: {inputs[\"bot_commands\"]}\n",
        "    Given the human instructions you have generated, provide a guide on how the robot would complete the task.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt3 = f\"\"\"\n",
        "    By referencing an observation in the image, ensure each instruction is accurate. Do not make assumptions.\n",
        "    Check that each instruction is logical.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt1 = \"USER: <image>\\n\" + prompt1 + \"​\\nASSISTANT: \"\n",
        "\n",
        "    output1 = pipe(\n",
        "        image, prompt=user_prompt1, generate_kwargs={\"max_new_tokens\": 4096}\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== OUTPUT 1 ===\\n\")\n",
        "    print(output1[0][\"generated_text\"])\n",
        "\n",
        "    user_prompt2 = (\n",
        "        user_prompt1\n",
        "        + output1[0][\"generated_text\"]\n",
        "        + \"\\nUSER: \"\n",
        "        + prompt2\n",
        "        + \"​\\nASSISTANT: \"\n",
        "    )\n",
        "\n",
        "    output2 = pipe(\n",
        "        image, prompt=user_prompt2, generate_kwargs={\"max_new_tokens\": 4096}\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== OUTPUT 2 ===\\n\")\n",
        "    print(output2[0][\"generated_text\"])\n",
        "\n",
        "    user_prompt3 = (\n",
        "        user_prompt2\n",
        "        + output2[0][\"generated_text\"]\n",
        "        + \"\\nUSER: \"\n",
        "        + prompt3\n",
        "        + \"​\\nASSISTANT: \"\n",
        "    )\n",
        "\n",
        "    output3 = pipe(\n",
        "        image, prompt=user_prompt3, generate_kwargs={\"max_new_tokens\": 4096}\n",
        "    )\n",
        "\n",
        "    return {\"bot_inst\": output3[0][\"generated_text\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kIXu7ozxYtjE"
      },
      "outputs": [],
      "source": [
        "# Robot commands available\n",
        "bot_commands = \"\"\"\n",
        "    1. move_to(x, y)\n",
        "    2. grab(object)\n",
        "    3. release(object)\n",
        "    4. push(object)\n",
        "    5. pull(object)\n",
        "    6. rotate(angle)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8XDkY34AYtjE"
      },
      "outputs": [],
      "source": [
        "# image_path = input(\"Enter the path of the image: \")\n",
        "# image_path = r\"images\\fridge_lefthandle.jpg\"\n",
        "# image_path = r\"images\\housedoor_knob_push.jpg\"\n",
        "# image_path = r\"images\\browndoor_knob_pull.jpg\"\n",
        "# image_path = r\"images\\labdoor_straighthandle_pull.jpg\"\n",
        "image_path = r\"images/bluedoor_knob_push.jpg\"\n",
        "# image_path = r\"images\\whitetable.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MSJy7iGDYtjE"
      },
      "outputs": [],
      "source": [
        "resize_image(image_path, image_path)\n",
        "image = load_image({\"image_path\": image_path})[\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu2VlUFuYtjE",
        "outputId": "0195a045-0767-4e93-91fb-dbd71e86ce93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the task to be performed: open the door\n"
          ]
        }
      ],
      "source": [
        "# Define the task to be performed\n",
        "task = input(\"Enter the task to be performed: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "49e2b5c71ae9441f9b1f165618465c2c",
            "2dbd5953c42646a8af33deeb68e16c1f",
            "5b7a2dee2dac4d1fb2044e577af0e915",
            "039a7b38c3934422a60fd77cfabaecdd",
            "be0064f4da524435a8f81a1247f3e8f8",
            "423dfcf8b1804939a495483832e22d54",
            "7d3bc2d8374a4dc59fe075a28b2f0c50",
            "3c8d18d88e644e6195a2c49c8f392dbf",
            "58b20e22b12846388636c6d253910f58",
            "cd35d1337e2a46de810e7ceba824c47e",
            "27b31a0db7d44351be421b8caf4c8d3c"
          ]
        },
        "id": "y3YPwcFDYtjE",
        "outputId": "6bcb4359-b4d3-43ef-f69b-5aeca64d248a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49e2b5c71ae9441f9b1f165618465c2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== OUTPUT 1 ===\n",
            "\n",
            "USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation - Instruction\".\n",
            "        ​\n",
            "ASSISTANT: 1. Observe the given image and its details.\n",
            "2. Identify the blue door with a knob and a lock.\n",
            "3. Locate the knob on the door.\n",
            "4. Gently turn the knob to the left.\n",
            "5. As the knob turns, the lock mechanism will engage, and the door will begin to open.\n",
            "6. Once the door is open, continue to hold the knob to keep it open.\n",
            "7. If the door is heavy or requires additional support, use the door frame or a wall to provide additional support.\n",
            "8. If the door is particularly heavy, consider using a door stop or a door wedge to prevent it from closing.\n",
            "\n",
            "These instructions are based on the image and the given context.\n",
            "\n",
            "=== OUTPUT 2 ===\n",
            "\n",
            "USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation - Instruction\".\n",
            "        ​\n",
            "ASSISTANT: USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation - Instruction\".\n",
            "        ​\n",
            "ASSISTANT: 1. Observe the given image and its details.\n",
            "2. Identify the blue door with a knob and a lock.\n",
            "3. Locate the knob on the door.\n",
            "4. Gently turn the knob to the left.\n",
            "5. As the knob turns, the lock mechanism will engage, and the door will begin to open.\n",
            "6. Once the door is open, continue to hold the knob to keep it open.\n",
            "7. If the door is heavy or requires additional support, use the door frame or a wall to provide additional support.\n",
            "8. If the door is particularly heavy, consider using a door stop or a door wedge to prevent it from closing.\n",
            "\n",
            "These instructions are based on the image and the given context.\n",
            "USER: \n",
            "        Imagine you are in control of a robotic arm with the following commands: \n",
            "    1. move_to(x, y)\n",
            "    2. grab(object)\n",
            "    3. release(object)\n",
            "    4. push(object)\n",
            "    5. pull(object)\n",
            "    6. rotate(angle)\n",
            "\n",
            "        Given the human instructions you have generated, provide a guide on how the robot would complete the task.\n",
            "        ​\n",
            "ASSISTANT: 1. move\\_to(the\\_blue\\_door)\n",
            "2. grab(the\\_blue\\_door)\n",
            "3. release(the\\_blue\\_door)\n",
            "4. push(the\\_blue\\_door)\n",
            "5. pull(the\\_blue\\_door)\n",
            "6. rotate(90)\n",
            "\n",
            "These instructions are based on the human instructions and the given context.\n"
          ]
        }
      ],
      "source": [
        "result = query(\n",
        "    {\n",
        "        \"image\": image,\n",
        "        \"task\": task,\n",
        "        \"bot_commands\": bot_commands,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVSX9L20YtjF",
        "outputId": "c0fc450b-51e2-4f29-b26a-ddde2c1be265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========\n",
            "\n",
            "USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation: Instruction\".\n",
            "        ​\n",
            "ASSISTANT: USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation: Instruction\".\n",
            "        ​\n",
            "ASSISTANT: 1. Observing the image, we can see that the door is blue and has a knob on it.\n",
            "2. To open the door, one would first need to find the knob on the door.\n",
            "3. Once found, the person would grip the knob firmly and turn it in the desired direction.\n",
            "4. As the knob is turned, the door will begin to open.\n",
            "5. The person should continue to turn the knob until the door is fully open.\n",
            "6. After the door is open, the person can then proceed to enter the building or room.\n",
            "\n",
            "Observation: Instruction.\n",
            "USER: \n",
            "        Imagine you are in control of a robotic arm with the following commands: \n",
            "    1. move_to(x, y)\n",
            "    2. grab(object)\n",
            "    3. release(object)\n",
            "    4. push(object)\n",
            "    5. pull(object)\n",
            "    6. rotate(angle)\n",
            "\n",
            "        Given the human instructions you have generated, provide a guide on how the robot would complete the task.\n",
            "        ​\n",
            "ASSISTANT: USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation: Instruction\".\n",
            "        ​\n",
            "ASSISTANT: USER:  \n",
            "\n",
            "        Observe the given image and its details.\n",
            "        Provide a detailed step-by-step guide on how a human would complete the task of: open the door.\n",
            "        Link each instruction to an observation in the image in this format: \"Observation: Instruction\".\n",
            "        ​\n",
            "ASSISTANT: 1. Observing the image, we can see that the door is blue and has a knob on it.\n",
            "2. To open the door, one would first need to find the knob on the door.\n",
            "3. Once found, the person would grip the knob firmly and turn it in the desired direction.\n",
            "4. As the knob is turned, the door will begin to open.\n",
            "5. The person should continue to turn the knob until the door is fully open.\n",
            "6. After the door is open, the person can then proceed to enter the building or room.\n",
            "\n",
            "Observation: Instruction.\n",
            "USER: \n",
            "        Imagine you are in control of a robotic arm with the following commands: \n",
            "    1. move_to(x, y)\n",
            "    2. grab(object)\n",
            "    3. release(object)\n",
            "    4. push(object)\n",
            "    5. pull(object)\n",
            "    6. rotate(angle)\n",
            "\n",
            "        Given the human instructions you have generated, provide a guide on how the robot would complete the task.\n",
            "        ​\n",
            "ASSISTANT: 1. The robotic arm is currently located at the starting position.\n",
            "2. The robotic arm should move to the desired location by executing the command \"move\\_to(x, y)\".\n",
            "3. Once the arm reaches the desired location, it should grab the object by executing the command \"grab(object)\".\n",
            "4. After successfully grabbing the object, the robotic arm should release the object by executing the command \"release(object)\".\n",
            "5. The robotic arm should then push the object by executing the command \"push(object)\".\n",
            "6. Finally, the robotic arm should rotate the object by executing the command \"rotate(angle)\".\n",
            "\n",
            "Observation: Instruction.\n",
            "USER: \n",
            "        By referencing an observation in the image, ensure each instruction is accurate. Do not make assumptions.\n",
            "        Check that each instruction is logical.\n",
            "        ​\n",
            "ASSISTANT: 1. The robotic arm is currently located at the starting position.\n",
            "2. The robotic arm should move to the desired location by executing the command \"move\\_to(x, y)\".\n",
            "3. Once the arm reaches the desired location, it should grab the object by executing the command \"grab(object)\".\n",
            "4. After successfully grabbing the object, the robotic arm should release the object by executing the command \"release(object)\".\n",
            "5. The robotic arm should then push the object by executing the command \"push(object)\".\n",
            "6. Finally, the robotic arm should rotate the object by executing the command \"rotate(angle)\".\n",
            "\n",
            "Observation: Instruction.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==========\\n\")\n",
        "print(result[\"bot_inst\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ivrVYoJjYtjF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039a7b38c3934422a60fd77cfabaecdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd35d1337e2a46de810e7ceba824c47e",
            "placeholder": "​",
            "style": "IPY_MODEL_27b31a0db7d44351be421b8caf4c8d3c",
            "value": " 3/3 [00:58&lt;00:00, 19.18s/it]"
          }
        },
        "27b31a0db7d44351be421b8caf4c8d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbd5953c42646a8af33deeb68e16c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423dfcf8b1804939a495483832e22d54",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3bc2d8374a4dc59fe075a28b2f0c50",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3c8d18d88e644e6195a2c49c8f392dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423dfcf8b1804939a495483832e22d54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e2b5c71ae9441f9b1f165618465c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dbd5953c42646a8af33deeb68e16c1f",
              "IPY_MODEL_5b7a2dee2dac4d1fb2044e577af0e915",
              "IPY_MODEL_039a7b38c3934422a60fd77cfabaecdd"
            ],
            "layout": "IPY_MODEL_be0064f4da524435a8f81a1247f3e8f8"
          }
        },
        "58b20e22b12846388636c6d253910f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b7a2dee2dac4d1fb2044e577af0e915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8d18d88e644e6195a2c49c8f392dbf",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58b20e22b12846388636c6d253910f58",
            "value": 3
          }
        },
        "7d3bc2d8374a4dc59fe075a28b2f0c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be0064f4da524435a8f81a1247f3e8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd35d1337e2a46de810e7ceba824c47e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
