{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "from src.utils.image_util import load_image, resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(inputs: dict) -> dict:\n",
    "        # Configure BitsAndBytesConfig based on GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16\n",
    "            )\n",
    "        else:\n",
    "            quantization_config = None  # or configure for CPU if necessary\n",
    "\n",
    "        model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "        # Initialize pipeline based on GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            pipe = pipeline(\n",
    "                \"image-to-text\",\n",
    "                model=model_id,\n",
    "                model_kwargs={\"quantization_config\": quantization_config},\n",
    "                device=0,  # use the first GPU\n",
    "            )\n",
    "        else:\n",
    "            pipe = pipeline(\n",
    "                \"image-to-text\",\n",
    "                model=model_id,\n",
    "                model_kwargs={\"quantization_config\": quantization_config},\n",
    "            )\n",
    "\n",
    "        image = inputs[\"image\"]\n",
    "\n",
    "        prompt1 = f\"\"\"\n",
    "        Observe the given image and its details.\n",
    "        Provide a detailed step-by-step guide on how a human would complete the task of: {inputs[\"task\"]}.\n",
    "        Link each instruction to an observation in the image in this format: \"Observation: Instruction\".\n",
    "        \"\"\"\n",
    "\n",
    "        prompt2 = f\"\"\"\n",
    "        Imagine you are in control of a robotic arm with the following commands: {inputs[\"bot_commands\"]}\n",
    "        Given the human instructions you have generated, provide a guide on how the robot would complete the task.\n",
    "        \"\"\"\n",
    "\n",
    "        prompt3 = f\"\"\"\n",
    "        By referencing an observation in the image, ensure each instruction is accurate. Do not make assumptions.\n",
    "        Check that each instruction is logical.\n",
    "        \"\"\"\n",
    "\n",
    "        user_prompt1 = \"USER: <image>\\n\" + prompt1 + \"​\\nASSISTANT: \"\n",
    "\n",
    "        output1 = pipe(\n",
    "            image, prompt=user_prompt1, generate_kwargs={\"max_new_tokens\": 200}\n",
    "        )\n",
    "\n",
    "        user_prompt2 = (\n",
    "            user_prompt1\n",
    "            + output1[0][\"generated_text\"]\n",
    "            + \"\\nUSER: \"\n",
    "            + prompt2\n",
    "            + \"​\\nASSISTANT: \"\n",
    "        )\n",
    "\n",
    "        output2 = pipe(\n",
    "            image, prompt=user_prompt2, generate_kwargs={\"max_new_tokens\": 200}\n",
    "        )\n",
    "\n",
    "        user_prompt3 = (\n",
    "            user_prompt2\n",
    "            + output2[0][\"generated_text\"]\n",
    "            + \"\\nUSER: \"\n",
    "            + prompt3\n",
    "            + \"​\\nASSISTANT: \"\n",
    "        )\n",
    "\n",
    "        output3 = pipe(\n",
    "            image, prompt=user_prompt3, generate_kwargs={\"max_new_tokens\": 200}\n",
    "        )\n",
    "\n",
    "        return {\"bot_inst\": output3[0][\"generated_text\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot commands available\n",
    "bot_commands = \"\"\"\n",
    "    1. move_to(x, y)\n",
    "    2. grab(object)\n",
    "    3. release(object)\n",
    "    4. push(object)\n",
    "    5. pull(object)\n",
    "    6. rotate(angle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = input(\"Enter the path of the image: \")\n",
    "# image_path = r\"images\\fridge_lefthandle.jpg\"\n",
    "# image_path = r\"images\\housedoor_knob_push.jpg\"\n",
    "# image_path = r\"images\\browndoor_knob_pull.jpg\"\n",
    "# image_path = r\"images\\labdoor_straighthandle_pull.jpg\"\n",
    "image_path = r\"images\\bluedoor_knob_push.jpg\"\n",
    "# image_path = r\"images\\whitetable.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_image(image_path, image_path)\n",
    "image = load_image({\"image_path\": image_path})[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the task to be performed\n",
    "task = input(\"Enter the task to be performed: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query(\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"task\": task,\n",
    "            \"bot_commands\": bot_commands,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"bot_inst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
